{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3.7.3 64-bit"},"language_info":{"name":"python","version":"3.7.3"},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Script and outputs for training a CNN for model selection, perform cross-validation and predict the most likely model from empirical data in the species *Euphorbia segueriana*.**\n","From the manuscript Kirschner & Perez et al. (2022) \"Congruent evolutionary responses of European steppe biota to late Quaternary climate change: insights from convolutional neural network-based demographic modeling\".\n","\n","All required files are available at the GitHub directory, except for the simulations, that can be downloaded here: https://drive.google.com/file/d/1GdTSSu_RwWAljqA8dpj-FW1juiojhJqb/view?usp=sharing. We will do the download with the next command."],"metadata":{"id":"ELhRS0fu2b6T"}},{"cell_type":"code","source":["#You also need to download the empirical data.\n","!wget https://raw.githubusercontent.com/ColonnaLab/EMBO_popgen/main/popgen2024/Manolo_Perez/Par1_Dem_Models_Esegueriana.txt\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1GdTSSu_RwWAljqA8dpj-FW1juiojhJqb' -O simulations.zip"],"metadata":{"id":"itLfhbv9F50J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Connect the notebook with your Google Drive.\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"RXeAzuOnQ9bf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Section 1: Building the CNN.**"],"metadata":{"id":"CP6hdNkPvgse"}},{"cell_type":"code","execution_count":null,"source":["# Import all required modules.\n","\n","import sys, os\n","import numpy as np\n","import time\n","import random\n","from random import shuffle, choice\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.models import load_model\n","#from keras.utils import np_utils\n","import sklearn.metrics as metrics\n","from sklearn.metrics import log_loss\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt"],"outputs":[],"metadata":{"id":"Zgc_VfbydhlW"}},{"cell_type":"markdown","source":["In the next cell we define the CNN architecture. Try to recognize each part of the architecture and associate them to the concepts presented during the lecture and what are their functions. Take notes if there is anything new or if you are not sure of what is the function of any of these parts."],"metadata":{"id":"OZDXy7uQ-X-B"}},{"cell_type":"code","source":["# Define parameters for the CNN run.\n","batch_size = 200\n","### how much interations to train the network\n","epochs = 100\n","\n","###n of models\n","num_classes = 3\n","\n","\n","# Define the CNN architecture.\n","def create_cnn(xtest):\n","\tinputShape = (xtest.shape[1], xtest.shape[2])\n","\t## image size. images need to have EXACTLY the same size\n","\tinputs = Input(shape=inputShape)\n","\tx = inputs\n","\t## 1D convolution - less computational intensive and is also invariant to the samples order;\n","\tx = Conv1D(250, kernel_size=2, activation='relu',input_shape=(xtest.shape[1], xtest.shape[2]))(x)\n","\t### Enables the network to learn more complex features / shapes.\n","\tx = AveragePooling1D(pool_size=2)(x)\n","\tx = BatchNormalization()(x)\n","\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n","\t### Enables the network to learn more complex features / shapes.\n","\tx = AveragePooling1D(pool_size=2)(x)\n","\tx = BatchNormalization()(x)\n","\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n","\t### Enables the network to learn more complex features / shapes.\n","\tx = AveragePooling1D(pool_size=2)(x)\n","\tx = BatchNormalization()(x)\n","\t### Linearising the image as in the initial step. From this point on the network behaves as a Multi-Layer Perceptron.\n","\tx = Flatten()(x)\n","\tx = Dense(125, activation='relu')(x)\n","\tx = Dropout(0.5)(x)\n","\tx = Dense(125, activation='relu')(x)\n","\tx = Dropout(0.5)(x)\n","\tx = Dense(num_classes, activation=\"softmax\")(x)\n","\n","\t# Construct the CNN.\n","\tmodel = Model(inputs, x)\n","\t# Return the CNN.\n","\treturn model"],"metadata":{"id":"sVQqlptu-fYB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Section 2: Train the network with 1,000 simulations from each model**\n","\n","Now we are going to load the simulated data and train the network. First, unzip the folder containing the simulations and load them as 3-dimensional NumPy arrays (simulation, SNPs, samples). Associate each simulation with the appropriate label and shuffle their order."],"metadata":{"id":"DQ6grKxjQO2T"}},{"cell_type":"code","source":["#Unzip simularions\n","!unzip \"/content/drive/MyDrive/simulations.zip\"\n","\n","#Load simulations from each model as a separate NumPy array\n","u1 = np.load(\"/content/simulations/trainingSims/simModel1.npy\",mmap_mode='r')\n","u2 = np.load(\"/content/simulations/trainingSims/simModel2.npy\",mmap_mode='r')\n","u3 = np.load(\"/content/simulations/trainingSims/simModel3.npy\",mmap_mode='r')\n","\n","# Combine all arrays.\n","x=np.concatenate((u1,u2,u3),axis=0)\n","\n","#For the real data we don't know which alleles are ancestral or derived.\n","#This function to transforms major alleles in -1 and minor in 1\n","for arr,array in enumerate(x):\n","  for idx,row in enumerate(array):\n","    if np.count_nonzero(row) > len(row)/2:\n","      x[arr][idx][x[arr][idx] == 1] = -1\n","      x[arr][idx][x[arr][idx] == 0] = 1\n","    else:\n","      x[arr][idx][x[arr][idx] == 0] = -1\n","\n","# Label each simulated array.\n","y=[0 for i in range(len(u1))]\n","y.extend([1 for i in range(len(u2))])\n","y.extend([2 for i in range(len(u3))])\n","y = np.array(y)\n","\n","#delete temporary files to free memory.\n","del (u1,u2,u3)\n","\n","# Shuffle the arrays for training, keeping the labels in the same order.\n","shf = list(range(len(x)))\n","shuffle(shf)\n","#Shuffle the labels (models)\n","y = y[shf]\n","#Shuffle the simulations using the same order of the labels.\n","x = x[shf]\n"],"metadata":{"id":"3M5ndWcXlSwE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print label and simulations length, these should be the same.\n","print (len(x), len(y))\n","\n","# Check array sizes as well just to be sure.\n","print (x.shape)\n","\n","print (y.shape)"],"metadata":{"id":"4GOMDoP9HMN4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's visualize the simulations as images. Check if you can extract some information from the images. For example, is it possible to separate individuals from the two different populations (remember that each sample is in a different column, and that the population samples are separated)."],"metadata":{"id":"jKVfoDvUBRWh"}},{"cell_type":"code","source":["#Print the label and export an image from the training data, to visualize its appearance\n","print(y[0])\n","import matplotlib.pyplot as plt\n","plt.imshow(x[0],cmap='gray', vmin=-1, vmax=1)"],"metadata":{"id":"K2tTL9ChmsbL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#You can also visualize a subset of the SNPs to better see the polymorphism.\n","import matplotlib.pyplot as plt\n","plt.imshow(x[0][0:200],cmap='gray', vmin=-1, vmax=1)"],"metadata":{"id":"NqjCb2iB_qDA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#you can also visualize the array values (-1 for major and 1 to minor).\n","x[0]"],"metadata":{"id":"NflhxA_JeTEy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we need to make the simulations look more like the real data. For that, we need to convert ancestral/derived alleles into major/minor. We also need to add missing data to the matrices."],"metadata":{"id":"_i3SZh6ECWlu"}},{"cell_type":"code","source":["# We will add missing data to the simulations as 0s.\n","# This is necessary beacuse the real data contains missing genotypes and\n","# we need to train the network to be able to recognize it.\n","\n","#Add missing data (coded as 0s) to the simulated matrices\n","# as a percentage according to the empirical data (15% in E. segueriana).\n","missD_perc = 15\n","missD = int(x.shape[1]*x.shape[2]*(missD_perc/100))\n","for i in range(x.shape[0]):\n","    indices_2d = np.random.choice(x.shape[1], size=missD, replace=True)\n","    indices_3d = np.random.choice(x.shape[2], size=missD, replace=True)\n","    x[i, indices_2d, indices_3d] = 0\n","del(missD)"],"metadata":{"id":"01LsKkU_oJrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Export an image from the training data, to visualize its appearance.\n","#Note how missing data (in grey) make it much more difficult to detect patterns.\n","import matplotlib.pyplot as plt\n","plt.imshow(x[0][0:200],cmap='gray', vmin=-1, vmax=1)"],"metadata":{"id":"4Sp-uu8BDCJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#And visualize the array values.\n","x[0]"],"metadata":{"id":"MzkynySLg51a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we need to separate the training simulations into the training and validation sets. Do you remember what are these sets used to? We don't need to define the test now, but do you remember what will it be used to?\n","\n","We will also compile the architecture, define the optimzer and set an Early Stopping approach."],"metadata":{"id":"yNf2ZYQ4DTXN"}},{"cell_type":"code","execution_count":null,"source":["# Separate train (75%) and validate (25%) sets.\n","xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n","ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n","del(x)\n","ytest = np.eye(num_classes)[ytest]\n","ytrain = np.eye(num_classes)[ytrain]\n","\n","# Create the CNN network.\n","model = create_cnn(xtest)\n","\n","# Compile the CNN.\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","\t              optimizer='Adam',\n","\t              metrics=['accuracy'])\n","\n","# We will use early stopping and save the model with the best val_accuracy.\n","earlyStopping = EarlyStopping(monitor='val_accuracy', patience=50, verbose=0, mode='max', restore_best_weights=True)\n","### stop training when validation error increases (wait 50 epochs to see if there is any improvement).\n","\n","# Check the architecture.\n","model.summary()\n"],"outputs":[],"metadata":{"id":"NJgkHTL9Tddn"}},{"cell_type":"code","source":["#We can also have a graphical visualization of the layers\n","!pip install git+https://github.com/paulgavrikov/visualkeras --upgrade\n","import visualkeras\n","from PIL import ImageFont\n","visualkeras.layered_view(model, legend=True)"],"metadata":{"id":"DoKMTcrLK4B8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["No it's time to train the network. This will take some time. While it's training we can discuss the previous steps of the script."],"metadata":{"id":"MksNycuRD6Za"}},{"cell_type":"code","source":["#Run the CNN\n","history = model.fit(xtrain, ytrain, batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(xtest, ytest),callbacks=[earlyStopping])\n","\n","# Save the model.\n","model.save(filepath='Trained_Esegueriana._MissingData.acc.mod')"],"metadata":{"id":"gjSGiOMTIDED"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After training we need to evaluate if the network is learning and not overfitting. The next commands will plot the accuracy in the training and validation sets."],"metadata":{"id":"cFqMMsBhERCL"}},{"cell_type":"code","source":["# Plot training and validation accuracies\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['training', 'validation'], loc='upper left')\n","plt.show()"],"metadata":{"id":"_b7zcHuy7aYv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["What do you think about this curves? Do you think that training was properly done? Can you think of ways to improve it?"],"metadata":{"id":"0527dUUNXCBg"}},{"cell_type":"markdown","source":["## **Section 3: Perform cross validation predictions with another 100 simulations per model. Those were not seen by the network during training**"],"metadata":{"id":"5l8HjILSQO2W"}},{"cell_type":"markdown","source":["Now we are going to test the trained model using the test set. These are new simulations that were not used by the network during the training. The idea here is to use simulaiton as if they are our real data (we call this pseudoobserved data in ABC) and see what the network predicts for each of these simulations. After that we compare the predicted values with the real (simulated) ones."],"metadata":{"id":"73mYpGECXzW9"}},{"cell_type":"code","execution_count":null,"source":["# Load Numpy test set arrays containing the test set simulations.\n","u1 = np.load(\"/content/simulations/testSims/simModel1.npy\",mmap_mode='r') #Expansion in both\n","u2 = np.load(\"/content/simulations/testSims/simModel2.npy\",mmap_mode='r') #Expansion in Zonal only\n","u3 = np.load(\"/content/simulations/testSims/simModel3.npy\",mmap_mode='r') #No expansion\n","\n","# Combine all test set arrays.\n","xtest=np.concatenate((u1,u2,u3),axis=0)\n","\n","#transform major alleles in -1 and minor 1\n","for arr,array in enumerate(xtest):\n","  for idx,row in enumerate(array):\n","    if np.count_nonzero(row) > len(row)/2:\n","      xtest[arr][idx][xtest[arr][idx] == 1] = -1\n","      xtest[arr][idx][xtest[arr][idx] == 0] = 1\n","    else:\n","      xtest[arr][idx][xtest[arr][idx] == 0] = -1\n","\n","# Label each simulated array.\n","ytest=[0 for i in range(len(u1))]\n","ytest.extend([1 for i in range(len(u2))])\n","ytest.extend([2 for i in range(len(u3))])\n","ytest = np.array(ytest)\n","\n","#delete temporary files to free memory.\n","del (u1,u2,u3)\n","\n","# Print label and simulations length, these should be the same.\n","print (len(xtest), len(ytest))\n","\n","#Add missing data (coded as 0s) to the simulated matrices\n","# as a percentage according to the empirical data (15% in E. segueriana).\n","missD_perc = 15\n","missD = int(xtest.shape[1]*xtest.shape[2]*(missD_perc/100))\n","for i in range(xtest.shape[0]):\n","    indices_2d = np.random.choice(xtest.shape[1], size=missD, replace=True)\n","    indices_3d = np.random.choice(xtest.shape[2], size=missD, replace=True)\n","    xtest[i, indices_2d, indices_3d] = 0\n","del(missD)\n","\n","# Predict with the trained model and export a confusion matrix.\n","pred = model.predict(xtest)\n","pred_cat = [i.argmax() for i in pred]\n","cm=confusion_matrix(ytest, pred_cat)\n","scenarios = ['Expansion_Z+ExZ', 'Expansion_Z', 'Stable']\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=scenarios)\n","\n","disp.plot(cmap=plt.cm.Blues)\n","plt.show()"],"outputs":[],"metadata":{"id":"pYZM0kNZQUfR"}},{"cell_type":"markdown","source":["Please take a moment to analyze the confusion matrix. Can you detect which models are more difficult to predict? For those, what is the other model that is creating this confusion?"],"metadata":{"id":"hcQvrejTYWpD"}},{"cell_type":"markdown","source":["## **Section 4: Predict the most likely model for the empirical data, using the trained CNN.**"],"metadata":{"id":"DH6qR1q8QO2Y"}},{"cell_type":"code","source":["# Load empirical data.\n","infile=np.loadtxt(\"/content/Par1_Dem_Models_Esegueriana.txt\")\n","inp=np.array(infile)\n","\n","inp.shape"],"metadata":{"id":"V-U7pUTUWSlD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"source":["# Create 100 subsets containing 1,000 random SNPs from the full empirical data.\n","num_samples=100\n","res = []\n","for i in range(0,num_samples):\n","\tidx = np.random.choice(inp.shape[0], 1000, replace=False)\n","\tn = inp[idx,:]\n","\tres.append(np.array(n))\n","\n","Emp = np.array(res)\n","\n","# Predict model probabilities for each of the 100 subsets.\n","Emp_pred = model.predict(Emp)\n","\n","# Print for each subset\n","print(Emp_pred)"],"outputs":[],"metadata":{"id":"0PGIawyJEDo0"}},{"cell_type":"code","source":["# Print the average of all subsets\n","np.mean(Emp_pred, axis=0)\n"],"metadata":{"id":"NShtsUMgPaUl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Which scenario was selected? Is this in agreement with the one obtained in the paper for *E. segueriana?* (model 2 - Zonal expansion only). Check with your colleagues whether they recovered the same scenario as you. If not, can you explain why this is the case?"],"metadata":{"id":"eQZ5YtjXQAhl"}},{"cell_type":"markdown","source":["## **Section 5: We can also perform parameter estimation.**"],"metadata":{"id":"7DAx-GF455tY"}},{"cell_type":"markdown","source":["Now we can use the same architecture (with a slight difference in the last layer) to perform parameter estimation. To make things simple, we will focus only in the simulations under the selected scenario (model 2). We will also need to change the labels of each simulation to the parameter values used."],"metadata":{"id":"Huxf6_csREDJ"}},{"cell_type":"code","source":["# Define a function to read the parameters file.\n","def readDemogParams(demogParamPath):\n","    params = []\n","    first = True\n","    with open(demogParamPath) as demogParamFile:\n","        for line in demogParamFile:\n","            params.append([float(x) for x in line.strip().split()])\n","    return params\n","\n","#define the architecture.\n","def create_cnn(xtest):\n","\tinputShape = (xtest.shape[1], xtest.shape[2])\n","\t## image size. images need to have EXACTLY the same size\n","\tinputs = Input(shape=inputShape)\n","\tx = inputs\n","\t## 1D convolution - less computational intensive and also treats snps as independent;\n","\tx = Conv1D(250, kernel_size=2, activation='relu',input_shape=(xtest.shape[1], xtest.shape[2]))(x)\n","\t### Enables the network to learn more complex features / shapes.\n","\tx = AveragePooling1D(pool_size=2)(x)\n","\tx = BatchNormalization()(x)\n","\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n","\t### Enables the network to learn more complex features / shapes.\n","\tx = AveragePooling1D(pool_size=2)(x)\n","\tx = BatchNormalization()(x)\n","\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n","\t### Enables the network to learn more complex features / shapes.\n","\tx = AveragePooling1D(pool_size=2)(x)\n","\tx = BatchNormalization()(x)\n","\t### Linearising the image as in the initial step. From this point on the network behaves as a Multi-Layer Perceptron.\n","\tx = Flatten()(x)\n","\tx = Dense(125, activation='relu',kernel_regularizer=l2(1e-3), bias_regularizer=l2(1e-3))(x)\n","\tx = Dropout(0.5)(x)\n","\tx = Dense(125, activation='relu',kernel_regularizer=l2(1e-3), bias_regularizer=l2(1e-3))(x)\n","\tx = Dropout(0.5)(x)\n","\t# The last layer is a dense according to the number of parameters.\n","\tx = Dense(numParams)(x)# Define the CNN architecture.\n","\n","\t# Construct the CNN.\n","\tmodel = Model(inputs, x)\n","\t# Return the CNN.\n","\treturn model"],"metadata":{"id":"R43u2FEK3xb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# Load parameters.\n","demogParams = readDemogParams('/content/simulations/trainingSims/parameters.txt')\n","y = np.array(demogParams)\n","numParams=y.shape[1]\n","\n","#delete temporary files to free memory.\n","del (demogParams)\n","\n","#We need to standard scale the parameters, as they can be on very different scales.\n","scaler= StandardScaler()\n","y = scaler.fit_transform(y)\n","\n","#Load simulations for the best model.\n","u3 = np.load(\"/content/simulations/trainingSims/simModel2.npy\",mmap_mode='r')\n","x = np.array(u3)\n","\n","#transform major alleles in -1 and minor 1\n","for arr,array in enumerate(x):\n","  for idx,row in enumerate(array):\n","    if np.count_nonzero(row) > len(row)/2:\n","      x[arr][idx][x[arr][idx] == 1] = -1\n","      x[arr][idx][x[arr][idx] == 0] = 1\n","    else:\n","      x[arr][idx][x[arr][idx] == 0] = -1\n","\n","# Print label and simulations length, these should be the same.\n","print (len(x), len(y))\n","\n","# Shuffle the arrays for training, keeping the labels in the same order.\n","shf = list(range(len(x)))\n","shuffle(shf)\n","y = y[shf]\n","x = x[shf]\n","\n","#Add missing data (coded as 0s) to the simulated matrices\n","# as a percentage according to the empirical data (15% in E. segueriana).\n","missD_perc = 15\n","missD = int(x.shape[1]*x.shape[2]*(missD_perc/100))\n","for i in range(x.shape[0]):\n","    indices_2d = np.random.choice(x.shape[1], size=missD, replace=True)\n","    indices_3d = np.random.choice(x.shape[2], size=missD, replace=True)\n","    x[i, indices_2d, indices_3d] = 0\n","del(missD)\n","\n","# Separate train (75%) and validate (25%) sets.\n","xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n","ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n","del(x)\n","\n","# Create the CNN network.\n","cnn = create_cnn(xtest)\n","\n","# Compile the CNN.\n","cnn.compile(loss='mean_squared_error', #the loss is now defined as the mean squared error, as we have continuous labels\n","\t              optimizer='Adam')\n","\n","# Check the architecture.\n","cnn.summary()\n","\n","# Run the CNN with early stopping. Save the model with the best val_accuracy.\n","earlyStopping = EarlyStopping(monitor='val_loss', patience=50, verbose=0, mode='max', restore_best_weights=True)\n","\n","history = cnn.fit(xtrain, ytrain, batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(xtest, ytest),callbacks=[earlyStopping])"],"metadata":{"id":"dQekJYiW75Yj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot training and validation accuracies\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"id":"I_pO0jbW-Yg7","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Now let's use the test set.**\n"],"metadata":{"id":"YUplory7Ri-W"}},{"cell_type":"code","source":["# Load the simulations.\n","x_test = np.load(\"/content/simulations/testSims/simModel2.npy\",mmap_mode='r')\n","x_test = np.array(x_test)\n","\n","#transform major alleles in -1 and minor 1\n","for arr,array in enumerate(xtest):\n","  for idx,row in enumerate(array):\n","    if np.count_nonzero(row) > len(row)/2:\n","      xtest[arr][idx][xtest[arr][idx] == 1] = -1\n","      xtest[arr][idx][xtest[arr][idx] == 0] = 1\n","    else:\n","      xtest[arr][idx][xtest[arr][idx] == 0] = -1\n","\n","\n","#Add missing data (coded as 0s) to the simulated matrices\n","# as a percentage according to the empirical data (15% in E. segueriana).\n","missD_perc = 15\n","missD = int(xtest.shape[1]*xtest.shape[2]*(missD_perc/100))\n","for i in range(xtest.shape[0]):\n","    indices_2d = np.random.choice(xtest.shape[1], size=missD, replace=True)\n","    indices_3d = np.random.choice(xtest.shape[2], size=missD, replace=True)\n","    xtest[i, indices_2d, indices_3d] = 0\n","del(missD)\n","\n","\n","# Predict parameters for each simulation.\n","pred = cnn.predict(x_test)\n","#return predictions to their correct scale.\n","pred = scaler.inverse_transform(pred)"],"metadata":{"id":"E-QCABiE_oVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Create 100 subsets containing 1,000 random SNPs from the full empirical data.\n","num_samples=100\n","res = []\n","for i in range(0,num_samples):\n","\tidx = np.random.choice(inp.shape[0], 1000, replace=False)\n","\tn = inp[idx,:]\n","\tres.append(np.array(n))\n","\n","# Predict parameters.\n","Emp_pred = np.array(res)\n","Emp_pred = cnn.predict(Emp_pred)\n","Emp_pred = scaler.inverse_transform(Emp_pred)\n","\n","#Print parameter names\n","print('Theta, T1, T2, T3, Ne, NeZ, NeExZLGM, NeZLGM, NeExZPl, NeZPl, m12_Pres, m21_Pres, m12_LGM, m21_LGM, m12_Pl, m21_Pl')\n","#Print parameter values (averaged over subsets)\n","print(np.mean(Emp_pred, axis=0))"],"metadata":{"id":"h41vO__GBBec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now you have just obtained an estimate of parameter values for the empirical data. Notice that these are point estimates (average over 100 subsets). Is this different from the type of results you obtained with ABC? Can you think of potential approaches to estimate uncertainty (feel free to try something below)?"],"metadata":{"id":"WPkv23yRZ96Y"}}]}